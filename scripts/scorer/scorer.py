import numpy as np
import pandas as pd
from  lifelines.metrics import concordance_index
import lifelines.metrics as metrics
from autogluon.core.metrics import make_scorer
from autogluon.tabular import TabularDataset

import logging
logger = logging.getLogger(__name__)

def scorefunct_cindex(y_true, y_pred):
    """
    Function to compute the concordance index between two arrays
    Parameters
    ----------
    y_true : array-like
        An array of true values representing survival times. Positive values indicate uncensored data 
        (i.e., actual event observed), and negative values indicate censored data (i.e., event not observed).
    
    y_pred : array-like
        An array of predicted values, typically risk scores or predicted survival times, that the model has generated.
    
    Returns
    -------
    concordance index
    """
    
    event=y_true>=0
    event=event.astype(int)
    time=np.abs(y_true)

    return concordance_index(time, y_pred, event_observed=event)

# concordance_index_custom_scorer = make_scorer(name='concordance_index',
#                                                   score_func=scorefunct_cindex,
#                                                   optimum=1,
#                                                   greater_is_better=True)


def scorefunct_coxPH(y_true, y_pred):
    """
        Computes the negative log-likelihood for the Cox Proportional Hazards model.

        This function calculates the negative log-likelihood based on the provided true survival times and predicted 
        risk scores. It uses the Cox Proportional Hazards model framework, considering censored data.

        Parameters
        ----------
        y_true : array-like
            An array of true values representing survival times. Positive values indicate uncensored data 
            (i.e., actual event observed), and negative values indicate censored data (i.e., event not observed).
        
        y_pred : array-like
            An array of predicted values, typically risk scores or predicted survival times, that the model has generated.
        
        Returns
        -------
        float
            The negative log-likelihood for the Cox Proportional Hazards model. Lower values indicate better model fit.
    """
    try:
        # Determine which observations are events
        event = y_true >= 0
        event = event.astype(int)
        
        # Extract the time (absolute value)
        time = np.abs(y_true)
        # Sort data by time
        sort_idx = np.argsort(time)
        # convert to list
        sort_idx = sort_idx.tolist()

        y_pred = y_pred[sort_idx]
        event = event[sort_idx]
        time = time[sort_idx]

        # Compute the cumulative sum of the exponential of the predicted values
        exp_y_pred = np.exp(y_pred)
        cum_risk_sum = np.flip(np.cumsum(np.flip(exp_y_pred)))

        # Only consider event times for the log-likelihood
        event_idx = np.where(event == 1)[0]

       # Compute the log-likelihood
        log_lik = np.sum(y_pred[event_idx] - np.log(cum_risk_sum[event_idx]))

        logger.info("Successfully computed the negative log-likelihood.")

        return -log_lik  # Return the negative log-likelihood
    except Exception as e:
        logger.error(f"An error occurred during the computation: {e}")
        raise

# coxPH_custom_scorer = make_scorer(name='coxPH', score_func=scorefunct_coxPH,
#                                                   optimum=-np.inf,
#                                                   greater_is_better=False)



def negative_log_likelihood_exponential(y_true, y_pred):
    """
    Function to compute the negative log-likelihood for exponential data with right-censored observations.
    
    Parameters
    ----------
    y_true : array-like
        An array of true values representing survival times. Positive values indicate uncensored data 
        (i.e., the event was observed), and negative values indicate censored data (i.e., the event was not observed).
    
    y_pred : array-like
        An array of predicted mean survival times (Âµ values) generated by the model.
    
    Returns
    -------
    negative log-likelihood
    
    """

    event = y_true >= 0
    event = event.astype(int)
    y_observed = np.abs(y_true)

    # Calculate the negative log-likelihood
    neg_log_likelihood = -np.sum(event * (np.log(y_pred) - y_observed / y_pred))

    return neg_log_likelihood





# example that dont run when loading the module
if __name__ == '__main__':
    # example
    y_true = np.array([-1, 2, 1, 4, 5, 1, 7, 8, 9, 10])
    y_pred = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
    print(scorefunct_cindex(y_true, y_pred))
    #print(concordance_index_custom_scorer(y_true, y_pred))


    # Example usage
    y_true = np.array([2, -3, 5, -6, 4])
    y_pred = np.array([0.5, 0.6, 0.7, 0.8, 0.9])

    print(scorefunct_coxPH(y_true, y_pred))
    #print(coxPH_custom_scorer(y_true, y_pred))

    # Example usage with TabularPredictor
    from autogluon.tabular import TabularPredictor
    from lifelines.datasets import load_rossi

    df = load_rossi()
    df['week'] = df['week'].astype(float)

    df_model=df.copy()

    # add a column time that is the the week column with negative values if censored and positive if not
    df_model['time'] = df_model['week']
    df_model.loc[df_model['arrest'] == 0, 'time'] = -df_model['week']

    # drop week and arrest columns
    df_model=df_model.drop(columns=['week', 'arrest'])

    # train model
    label = 'time'
    coxPH_custom_scorer=make_scorer(name='coxPH', score_func=scorefunct_coxPH, optimum=-np.inf, greater_is_better=False)
    predictor = TabularPredictor(label=label, eval_metric=coxPH_custom_scorer).fit(df_model, presets="good_quality")
    predictor.leaderboard(df_model, silent=True)
    predictions=predictor.predict(df_model)

    # compute concordance index
    print(concordance_index(df['week'], -predictions, event_observed=df['arrest']))

    # plot df['week'] against -predictions
    from matplotlib import pyplot as plt
    plt.scatter(df['week'], -predictions, c=df['arrest'])
    plt.xlabel('week')
    plt.ylabel('predictions')
    
    plt.show()

    # another example
    from lifelines.datasets import load_leukemia
    df = load_leukemia()
    df['t'] = df['t'].astype(float)

    df_model=df.copy()

    # add a column time that is the the week column with negative values if censored and positive if not
    df_model['time'] = df_model['t']
    df_model.loc[df_model['status'] == 0, 'time'] = -df_model['t']

    # drop t and status columns
    df_model=df_model.drop(columns=['t', 'status'])

    # train model
    label = 'time'
    df_model=TabularDataset(df_model)
    predictor = TabularPredictor(label=label, eval_metric=coxPH_custom_scorer).fit(df_model, presets="best_quality", time_limit=1000)
    predictor.leaderboard(df_model, silent=True)
    predictions=predictor.predict(df_model)

    # compute concordance index
    print(concordance_index(df['t'], -predictions, event_observed=df['status']))

    ##################
    negative_log_likelihood_exponential_custom_scorer = make_scorer(name='negative_log_likelihood_exponential',
                                                        score_func=negative_log_likelihood_exponential, 
                                                        optimum=-np.inf,
                                                        greater_is_better=False)

    predictor = TabularPredictor(label=label, eval_metric=negative_log_likelihood_exponential_custom_scorer).fit(df_model, presets="best_quality", time_limit=1000)
    predictor.leaderboard(df_model, silent=True)
    predictions=predictor.predict(df_model)

    # compute concordance index
    print(concordance_index(df['t'], -predictions, event_observed=df['status']))
   

    -predictions



